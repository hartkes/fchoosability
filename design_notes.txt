
2017-06-26:
For the subset generator for bitarrays, we use the standard first/next paradigm.  This results in code that looks like this:
    first()
    do
    {
        // do something with the subset
    } while (next());

For the subgraph generator, we only use next.  We initialize the data structures so that the first call to next produces the first subgraph.  The reason we do this is so that we are running several subgraph generators in parallel (because of the rooting issue).  Hence, the set of eligible vertices might change between calls to next for a specific subgraph generator (as calls might be made to *other* subgraph generators, and could fill up a vertex's list), and we need to take that account.  Thus, the subgraph cannot be already generated, waiting for us.

The code structure thus looks like this:
    initialize()
    while (next())
    {
        // do something with the subgraph
    }

The way that we achieve this is that we initialize cur_layer=0, and set up the bitarray of the 0th layer so that when next is called on it, it generates the root vertex.  The universe bitarray of the 0th layer must be initialized to have just the root.  We need to check the corner cases of what happens when the root is not eligible, or when the only subgraph generated is just the root (we do not generated singletons).

This also has the added benefit of simplifying the code, since now we don't need a first() that actually generates all the levels (this duplicated the code in next()).

2017-06-30:
For each new colorability class, we'd like to just say "give me another connected subgraph to consider".  However, our subgraph generator is rooted.  Thus, we have a generator rooted at each subgraph.  To make sure that we don't generate the same subgraph from different roots, we decree that the root is the highest indexed vertex in each subgraph.  We choose the highest index instead of the lowest, since then the low index vertices will be furthest from the root, and those change the most frequently according to our subset advance technique.  Thus, when we obtain a color class from a feasible coloring, the assumption is that vertices of the color class will probably be close to the root, and hopefully we can advance quite a bit.  Of course, the most important thing here is the levels away from the root (which has nothing to do with the index of the vertices), but we'll try this.  It also makes a bunch of the bit masks very simple.

2017-07-25:
There's a problem that a high-index vertex might have no colors in its list (L[v]==0), but that all of the generators at that vertex and higher are not eligible.  So all of the work from that point on is doomed, since there are no subgraphs that can be generated that contain that vertex.  
Additionally, when picking the next generator, it might well be *lower indexed* than a vertex v with L[v]==0, and so v has no hope of being generated.
But there's an issue: singletons don't occur until the end.  So we *know* this vertex *must* be put in as a singleton.  Maybe once we detect this, we just add a colorability class consisting of the singleton?  Or we could modify "vertices_to_skip", but the hope was to eliminate that from the has_feasible() function code for most calls.

2017-08-14:
There are still some ongoing issues about how to handle singletons and when to detect that there is an actual bad list.

Previously: singletons were not explicitly generated.  Thus, any partial list assignment could be expanded to full list assignment (where each vertex has a full list) by adding singletons at the end.  When no more subgraphs could be added to a partial list assignment (either because the vertices' lists are full, or the subgraph generators are finished), we add singletons (virtually using vertices_to_skip) and check if there is a feasible coloring.

The problem as noted above arises if (after a while) there is a vertex with an empty list that has no remaining way to have a color added to its list.  When this detected, ideally we would just add a singleton.  But in the previous scheme, singletons were only added at the end.  So a lot of time was wasted adding other subgraphs and checking for feasible colorings (there aren't any), until running out of subgraphs and adding the singleton.  This is inefficient.

New plan:  I changed the subgraph generator to generate the singletons as the last subgraph.  Now the singletons are treated just like every other subgraph, and can be generated as needed.  However, now it's difficult to tell if a partial list assignment that can't be expanded and without a feasible coloring is a counterexample or not.  Perhaps we backed up to this partial list assignment.  And the test code I wrote fails, identifying such partial list assignments as counterexamples when they are not.  I attempted to add a flag indicating whether we had backtracked to this partial list assignment or not, but this also failed.

What should happen when a singleton is added?  Should the vertex be marked as ineligible (ie, its list is full)?  But what if a subgraph going through that vertex needs to be added?

Is all of this compatible with the assumption that colorability classes are connected?

Another issue: I wanted to restrict the multiplicity of a colorability class to its number of vertices.  But again we have the issue of whether a partial list coloring is a counterexample or not.  Perhaps a lemma can be proved here?  We need some reasonable bound on the f[v]s, namely that there are at most the degree.

Also: The Small Pot Lemma should apply to everything I've been talking about above.  It seems independent of those issues.  A good example of sharpness in the Small Pot Lemma: colorability classes of size 2 that form a tree.

2017-10-05:
I modified the code.  This version has singletons as subgraphs generated by the subgraph generator just like all the other subgraphs.  There is no bound on the multiplicity of colorability classes.  Thus, bad list assignments are list assignments that are full and have no feasible coloring.

I also added the Small Pot Lemma.

After these changes, I seem to be getting the right answers, but the run times are much slower than what I had previously recorded in input_test.txt.  It also seems that the count is much larger, so the discrepancy cannot be accounted for with just the overhead of doing these additional tests.

Maybe the increase is coming from adding singletons as special subgraphs?

I wonder how much the multiplicity changes would improve things.

